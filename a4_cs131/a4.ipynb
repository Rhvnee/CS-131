{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbc121e30a2defb3",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TaxiFarePrediction\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d9ba64bea7f427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:============================>                            (6 + 6) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vendorid: double (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- ratecodeid: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- pulocationid: double (nullable = true)\n",
      " |-- dolocationid: double (nullable = true)\n",
      " |-- payment_type: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|vendorid|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|ratecodeid|store_and_fwd_flag|pulocationid|dolocationid|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|     1.0| 2019-04-01 00:04:09|  2019-04-01 00:06:35|            1.0|          0.5|       1.0|                 N|       239.0|       239.0|         1.0|        4.0|  3.0|    0.5|       1.0|         0.0|                  0.3|         8.8|                 2.5|\n",
      "|     1.0| 2019-04-01 00:22:45|  2019-04-01 00:25:43|            1.0|          0.7|       1.0|                 N|       230.0|       100.0|         2.0|        4.5|  3.0|    0.5|       0.0|         0.0|                  0.3|         8.3|                 2.5|\n",
      "|     1.0| 2019-04-01 00:39:48|  2019-04-01 01:19:39|            1.0|         10.9|       1.0|                 N|        68.0|       127.0|         1.0|       36.0|  3.0|    0.5|      7.95|         0.0|                  0.3|       47.75|                 2.5|\n",
      "|     1.0| 2019-04-01 00:35:32|  2019-04-01 00:37:11|            1.0|          0.2|       1.0|                 N|        68.0|        68.0|         2.0|        3.5|  3.0|    0.5|       0.0|         0.0|                  0.3|         7.3|                 2.5|\n",
      "|     1.0| 2019-04-01 00:44:05|  2019-04-01 00:57:58|            1.0|          4.8|       1.0|                 N|        50.0|        42.0|         1.0|       15.5|  3.0|    0.5|      3.85|         0.0|                  0.3|       23.15|                 2.5|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "# file is named '2019-04.csv' and is in the same directory\n",
    "df = spark.read.csv(\"2019-04.csv\", header=True, inferSchema=True)\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e6625f85719626d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+------------+------------+\n",
      "|passenger_count|PULocationID|DOLocationID|total_amount|\n",
      "+---------------+------------+------------+------------+\n",
      "|            1.0|       239.0|       239.0|         8.8|\n",
      "|            1.0|       230.0|       100.0|         8.3|\n",
      "|            1.0|        68.0|       127.0|       47.75|\n",
      "|            1.0|        68.0|        68.0|         7.3|\n",
      "|            1.0|        50.0|        42.0|       23.15|\n",
      "|            1.0|        95.0|       196.0|         9.8|\n",
      "|            1.0|       211.0|       211.0|         6.8|\n",
      "|            1.0|       237.0|       162.0|         7.8|\n",
      "|            1.0|       148.0|        37.0|        20.3|\n",
      "|            1.0|       265.0|       265.0|        0.31|\n",
      "+---------------+------------+------------+------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Select Relevant Columns\n",
    "# 4th = passenger_count, 8th = PULocationID, 9th = DOLocationID, 17th = total_amount\n",
    "\n",
    "selected = df.select(\"passenger_count\", \"PULocationID\", \"DOLocationID\", \"total_amount\")\n",
    "selected.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10a120108952e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Missing or Null Data\n",
    "selected = selected.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2bbafba020bfc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "trainDF, testDF = selected.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f71532dc8084b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble Features\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"passenger_count\", \"PULocationID\", \"DOLocationID\"],\n",
    "    outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e76004067b08d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Decision Tree Regressor\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"total_amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "908dbafa6d21810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec7aa93a54c49ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:>                                                       (0 + 12) / 12]"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "model = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68e5f8700dd0ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+------------+------------------+\n",
      "|passenger_count|PULocationID|DOLocationID|        prediction|\n",
      "+---------------+------------+------------+------------------+\n",
      "|            0.0|         3.0|       136.0|18.005014552242418|\n",
      "|            0.0|         4.0|        75.0| 15.64471842503167|\n",
      "|            0.0|         4.0|        87.0| 15.64471842503167|\n",
      "|            0.0|         4.0|       113.0| 15.64471842503167|\n",
      "|            0.0|         4.0|       234.0|18.005014552242418|\n",
      "|            0.0|         7.0|       121.0|18.005014552242418|\n",
      "|            0.0|         7.0|       193.0|18.005014552242418|\n",
      "|            0.0|        10.0|       100.0| 15.64471842503167|\n",
      "|            0.0|        12.0|       142.0|18.005014552242418|\n",
      "|            0.0|        12.0|       211.0|18.005014552242418|\n",
      "+---------------+------------+------------+------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Make Predictions\n",
    "predictions = model.transform(testDF)\n",
    "predictions.select(\"passenger_count\", \"PULocationID\", \"DOLocationID\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "671c2265715432f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                       (0 + 12) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 12.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Evaluate with RMSE\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"total_amount\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
